{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create new project for analysis and call the project and active map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#if running this code outside of ArcGIS Pro put the project file path in quotes in place of CURRENT\n",
    "#if running this project in Pro, open this Notebook and the map that will contain the data for the analysis\n",
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "mp = aprx.listMaps(\"Access*\")[0]\n",
    "print(mp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add USA Parks to the map\n",
    "**Last updated: 2024-11-11**\n",
    "\n",
    "Tasks: \n",
    "- Import the ArcGIS API for Python library\n",
    "- Access ArcGIS Online and the USA Parks item (need to search for the correct item and copy the item ID): https://uw-mad.maps.arcgis.com/home/item.html?id=e49e181ac82c46edac3ae601ebb3ef2d \n",
    "- Extract the feature layer and export it to the project file geodatabase - this will save it locally as a File Geodatabase Feature Class and add it to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#access ArcGIS Online\n",
    "portal = GIS(\"home\")\n",
    "\n",
    "#access USA Parks feature service\n",
    "parks_id = \"e49e181ac82c46edac3ae601ebb3ef2d\"\n",
    "\n",
    "parks_item = portal.content.get(parks_id)\n",
    "parks_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_parks_fc = \"USA_Parks_export\"\n",
    "#put filepath for project geodatabase in the quotes\n",
    "gdb = r\"\"\n",
    "\n",
    "#access feature layer\n",
    "parks_fl = parks_item.layers[0]\n",
    "\n",
    "#use query to return a feature set object\n",
    "export = parks_fl.query()\n",
    "\n",
    "#save feature set as a feature class in the project geodatabase\n",
    "export.save(gdb, out_parks_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add all 2020 TIGER/Line census block shapefiles to the map\n",
    "**Created by GL, edited by JH, Last updated: 2024-11-11**\n",
    "\n",
    "2020 Census TIGER/Line Tabulation Block Shapefiles were used for this calculation. Tabulation blocks had population and housing counts for each census block. The record layout can be found here: https://www.census.gov/programs-surveys/geography/technical-documentation/complete-technical-documentation/tiger-geo-line.2020.html#list-tab-GV16DOVS6MWQBLMN86. The shapefiles for each state had to be downloaded and unzipped manually. Download here: https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2020.html#list-tab-790442341 \n",
    "\n",
    "Note: The CT statecode (09) was excluded from the dataframe used to add census block shapefiles to the map.. The census tabulation block GEOIDs for Connecticut still reflect the old CT counties. They need to be crosswalked to the new census block GEOIDs that go with the planning regions (new CT county equivalents). The crosswalk can be found here: https://github.com/CT-Data-Collaborative/2022-block-crosswalk. \n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "- create a dataframe that has following columns:\n",
    "    - \"statecode\", two-digit state fipscode for all states except CT (09)\n",
    "    - \"file_path\" (for shapefiles)\n",
    "- loop through \"file_path\" to add shapefiles to map, i.e., `mp.addDataFromPath(shp_path)`\n",
    "- crosswalk old CT census block GEOIDs to new CT census block GEOIDs\n",
    "    - read in csv with crosswalk as a pandas dataframe, drop un-needed fields, convert all columns to strings with leading zeros\n",
    "    - in pandas dataframe crosswalk, rename block_fips_2022 to GEOID20 (necessary to join to CT 2020 census block file)\n",
    "    - read in CT 2020 census block shapefile as a spatially enabled dataframe\n",
    "    - join census block spatially enabled dataframe to crosswalk with a left outer join on GEOID20 (census block spatially enabled dataframe needs to be the left data frame becuase it has more rows and the left outer join will retain those rows; the crosswalk dropped some census blocks that had no population)\n",
    "    - after join, rename GEOID20 to old_GEOID20 and COUNTYFP20 to old_COUNTYFP20 and then drop GEOID20 and COUNTYFP20\n",
    "    - then rename block_fips_2022 (new census block fipscodes) to GEOID20 and name a substring of the last three digits of ce_fips_2022 (new county equivalent fipscodes) COUNTYFP20 to match other census block shapefile column names\n",
    "    - convert the spatially enabled dataframe to a feature class following the naming convention of the other census block shapefiles (Note: it will be a feature class saved in the project geodatabase while the rest of the census block layers are shapefiles saved on external hard drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#list of state fips codes\n",
    "#purposefully excluding state code 09 (CT)\n",
    "statecode = [str(code).zfill(2) for code in list(range(57)) if code not in (0, 3, 7, 9, 14, 43, 52)]\n",
    "\n",
    "#create dataframe with a column 'statecode'\n",
    "df = pd.DataFrame(statecode, columns=[\"statecode\"])\n",
    "\n",
    "#put the root of the filepath where the TIGER/Line census tabulation blocks are saved before /tl_2020_\n",
    "dir_base = \"/tl_2020_\" \n",
    "\n",
    "#add columns of 'file_path', 'tabblock', 'intersect'\n",
    "df[\"file_path\"] = dir_base + df[\"statecode\"] + \"_tabblock20.shp\" #end of the TIGER/Line census tabulation block shapefile name\n",
    "#df[\"tabblock\"] = \"tl_2020_\" + df[\"statecode\"] + \"_tabblock20\"\n",
    "#df[\"intersect\"] = \"block_\" + df[\"statecode\"] + \"_intersect\"\n",
    "\n",
    "#print(df)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add shapefiles to map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#try the first two states\n",
    "for i in range(2):\n",
    "    print(df.iloc[i,1])\n",
    "    mp.addDataFromPath(df.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#helpful to pause drawing on map before running \n",
    "#loop through all states\n",
    "for i in range(len(df)):\n",
    "    print(df.iloc[i,1])\n",
    "    mp.addDataFromPath(df.iloc[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosswalk CT census block GEOIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in crosswalk csv - put filepath of wherever crosswalk .csv is saved in quotes\n",
    "ct_crosswalk = pd.read_csv(r\"\")\n",
    "\n",
    "#show contents of csv\n",
    "ct_crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #subsetting dataframe to just the columns needed \n",
    "ct_crosswalk_2 = ct_crosswalk[['block_fips_2020', 'block_fips_2022', 'ce_fips_2022']]\n",
    "\n",
    "ct_crosswalk_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all columns to strings, add leading zeros, change column name block_fips_2020 to GEOID20 so it can be joined to the census block geography file\n",
    "ct_crosswalk_2 = ct_crosswalk_2.astype(str)\n",
    "\n",
    "ct_crosswalk_2['GEOID20'] = ct_crosswalk_2['block_fips_2020'].str.zfill(15)\n",
    "ct_crosswalk_2['block_fips_2022'] = ct_crosswalk_2['block_fips_2022'].str.zfill(15)\n",
    "ct_crosswalk_2['ce_fips_2022'] = ct_crosswalk_2['ce_fips_2022'].str.zfill(5)\n",
    "\n",
    "ct_crosswalk_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retain only the block_fips_2022, GEOID20, and COUNTYFP20 column names\n",
    "ct_crosswalk_3 = ct_crosswalk_2[['GEOID20', 'block_fips_2022', 'ce_fips_2022']]\n",
    "\n",
    "ct_crosswalk_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert tl_2020_09_tabblock_20 (using filepath from whevever the census tabulation block shapefiles are saved on your local machine) to spatially enabled dataframe to manipulate columns \n",
    "CT = pd.DataFrame.spatial.from_featureclass(r'\\tl_2020_09_tabblock20.shp')\n",
    "\n",
    "CT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#join crosswalk (ct_crosswalk_3) to census block geography file (CT)\n",
    "#left outer join using the merge function, CT should be left dataframe\n",
    "CT_join = pd.merge(\n",
    "    CT, ct_crosswalk_3, how = \"left\", on = [\"GEOID20\"]\n",
    "    )\n",
    "\n",
    "#show contents of join\n",
    "CT_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename GEOID20 (old census block fipscode) and COUNTYFP20 (old county fipscode)\n",
    "CT_join['old_COUNTYFP20'] = CT_join['COUNTYFP20']\n",
    "CT_join['old_GEOID20'] = CT_join['GEOID20']\n",
    "\n",
    "CT_join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop GEOID20 (old census block fipscode) and COUNTYFP20 (old county fipscode)\n",
    "CT_join_2 = CT_join.drop(columns = ['GEOID20', 'COUNTYFP20'])\n",
    "\n",
    "CT_join_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename block_fips_2022 (new census block fipscodes) to GEOID20 \n",
    "#take substring of last three characters of ce_fips_2022 (new county equivalent fipscodes) and name COUNTYFP20 \n",
    "#to match other census block shapefile columns\n",
    "CT_join_2['GEOID20'] = CT_join_2['block_fips_2022']\n",
    "CT_join_2['COUNTYFP20'] = CT_join_2['ce_fips_2022'].str.slice(2, 5)\n",
    "\n",
    "CT_join_3 = CT_join_2.drop(columns = ['block_fips_2022', 'ce_fips_2022'])\n",
    "\n",
    "#CT_join_2.head()\n",
    "CT_join_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert spatial data frame back to a feature class in project geodatabase\n",
    "CT_join_3.copy().spatial.to_featureclass(location = gdb + r\"\\tl_2020_09_tabblock20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2024-11-11 Note: I did a visual inspection of the tl_2020_09_tabblock20 feature class attribute table, and there are 65 census blocks missing from the crosswalk. The github page for the crosswalk noted that census blocks in 2020 census tracts that contained only water were excluded. Confirmed in the attribute table that all blocks that didn't have a join with a block in the crosswalk have 0 population (sort geoid20 field ascending to see this). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Change coordinate system\n",
    "**Last updated: 2024-11-11**\n",
    "\n",
    "The USA Parks feature class from the Esri Living Atlas is in the WGS 1984 geographic coordinate system (GCS). \n",
    "The TIGER/Line Census Block and County boundary files are in the NAD 1983 GCS. \n",
    "For this calculation, USA Parks will be re-projected to the NAD 1983 GCS to match the Census files. \n",
    "\n",
    "Leave all inputs unprojected - there is no map projection that is appropriate for the entire U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters were set with the tool interface and the Python command was copied to ensure information about the geographic transformation was correct\n",
    "#arcpy.management.Project(in_dataset, out_dataset, out_coor_system, {transform_method}, {in_coor_system}, {preserve_shape}, {max_deviation}, {vertical})\n",
    "\n",
    "arcpy.management.Project(\n",
    "    in_dataset=\"USA_Parks_export\",\n",
    "    out_dataset=\"USA_Parks_NAD1983\",\n",
    "    out_coor_system='GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]',\n",
    "    transform_method=\"WGS_1984_(ITRF00)_To_NAD_1983\",\n",
    "    in_coor_system='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]',\n",
    "    preserve_shape=\"NO_PRESERVE_SHAPE\",\n",
    "    max_deviation=None,\n",
    "    vertical=\"NO_VERTICAL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create 1/2 mile buffer around parks \n",
    "Use the geodesic method, which accounts for the shape of the Earth and is more appropriate for inputs that cover large regions (see tool documentation https://pro.arcgis.com/en/pro-app/2.8/tool-reference/analysis/pairwise-buffer.htm and \"How Buffer Analysis Works\" https://pro.arcgis.com/en/pro-app/latest/tool-reference/analysis/how-buffer-analysis-works.htm). With the geodesic method, distances are calculated between two points on a curved surface (the geoid). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcpy.analysis.PairwiseBuffer(\"USA_Parks_NAD1983\", \"Parks_GeodesicBuffer\", \"0.5 Miles\", \"ALL\", None, \"GEODESIC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersect Parks_GeodesicBuffer with 2020 TIGER/Line census blocks\n",
    "**Created by GL, edited by JH, Last updated: 2024-11-12**\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "- create a dataframe that has following columns:\n",
    "    - \"statecode\", two-digit state fipscode for all states (**Note**: you must run the step to create a new dataframe with statecode defined to include CT before running the intersect step)\n",
    "    - \"tabblock\" and \"intersect\"\n",
    "- loop through \"tabblock\" and \"intersect\" for arcpy.analysis.Intersect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for dataframe copied from above, this time need all states in statecode\n",
    "#list of state fips codes\n",
    "statecode_2 = [str(code).zfill(2) for code in list(range(57)) if code not in (0, 3, 7, 14, 43, 52)]\n",
    "\n",
    "#create dataframe with a column 'statecode'\n",
    "df_2 = pd.DataFrame(statecode_2, columns=[\"statecode\"])\n",
    "\n",
    "#add columns of 'tabblock', 'intersect'\n",
    "#df[\"file_path\"] = dir_base + df[\"statecode\"] + \"_tabblock20.shp\" #end of the TIGER/Line census tabulation block shapefile name\n",
    "df_2[\"tabblock\"] = \"tl_2020_\" + df_2[\"statecode\"] + \"_tabblock20\"\n",
    "df_2[\"intersect\"] = \"block_\" + df_2[\"statecode\"] + \"_intersect\"\n",
    "\n",
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop: arcpy.analysis.Intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#try the first 3 \n",
    "#arcpy.analysis.Intersect(in_features, out_feature_class, {join_attributes}, {cluster_tolerance}, {output_type})\n",
    "\n",
    "for i in (0, 1, 2):\n",
    "    print(f\"{df_2.iloc[i,1]}, {df_2.iloc[i,2]}\")\n",
    "    #arcpy.analysis.Intersect([df_2.iloc[i,1],\"Parks_GeodesicBuffer\"], df_2.iloc[i,2], \"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop through all the states\n",
    "#arcpy.analysis.Intersect(in_features, out_feature_class, {join_attributes}, {cluster_tolerance}, {output_type})\n",
    "\n",
    "for i in range(len(df_2)):\n",
    "    print(f\"{df_2.iloc[i,1]}, {df_2.iloc[i,2]}\")\n",
    "    arcpy.analysis.Intersect([df_2.iloc[i,1],\"Parks_GeodesicBuffer\"], df_2.iloc[i,2], \"ALL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate total pop and pop with access to parks to county level\n",
    "Find the total population in each county by taking the sum of POP20 field for all census blocks in a county (denominator). Find the population that has access to a park in each county by taking the sum of the POP20 field for all census blocks that intersect with Parks_GeodesicBuffer (numerator). Divide population with access to parks by total population. \n",
    "\n",
    "**Created by JH, edited from code written by GL, Last updated 2024-11-22**\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "- create a dataframe that has following columns:\n",
    "    - \"statecode\", two-digit state fipscode for all states\n",
    "    - \"tabblock\" and \"intersect\"\n",
    "    - \"totalPop\" and \"accessPop\"\n",
    "- loop through aggregating the population with access to parks and the total population to the county level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#if you haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list of state fips codes including CT (09)\n",
    "statecode = [str(code).zfill(2) for code in list(range(57)) if code not in (0, 3, 7, 14, 43, 52)]\n",
    "\n",
    "#create dataframe with a column 'statecode' \n",
    "df_3 = pd.DataFrame(statecode, columns=[\"statecode\"])\n",
    "\n",
    "#add columns of 'tabblock', 'intersect', 'totalPop', 'accessPop'\n",
    "df_3[\"tabblock\"] = \"tl_2020_\" + df_3[\"statecode\"] + \"_tabblock20\"\n",
    "df_3[\"intersect\"] = \"block_\" + df_3[\"statecode\"] + \"_intersect\"\n",
    "df_3[\"totalPop\"] = \"county_\" + df_3[\"statecode\"] + \"_totalPop\"\n",
    "df_3[\"accessPop\"] = \"county_\" + df_3[\"statecode\"] + \"_accessPop\"\n",
    "\n",
    "print(df_3)\n",
    "\n",
    "#df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loop: arcpy.analysis.Statistics and arcpy.analysis.AlterField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#aggregate total county population - input is all census blocks - and rename \"SUM_POP20\" to \"parks_denominator\"\n",
    "#arcpy.analysis.Statistics(in_table, out_table, {statistics_fields}, {case_field}, {concatenation_separator})\n",
    "#arcpy.management.AlterField(in_table, field, {new_field_name}, {new_field_alias}, {field_type}, {field_length}, {field_is_nullable}, {clear_field_alias})\n",
    "\n",
    "for i in range(len(df_3)):\n",
    "    print(f\"{df_3.iloc[i,1]}, {df_3.iloc[i,3]}\")\n",
    "    arcpy.analysis.Statistics((df_3.iloc[i,1]), (df_3.iloc[i,3]), [[\"POP20\", \"SUM\"]], [\"STATEFP20\", \"COUNTYFP20\"])\n",
    "    print(f\"{df_3.iloc[i,3]}\")\n",
    "    arcpy.management.AlterField((df_3.iloc[i,3]), \"SUM_POP20\", \"v179_denominator\", \"v179_denominator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#aggregate county population with access to parks - input is intersected census blocks - and rename \"SUM_POP20\" to \"parks_numerator\"\n",
    "\n",
    "for i in range(len(df_3)):\n",
    "    print(f\"{df_3.iloc[i,2]}, {df_3.iloc[i,4]}\")\n",
    "    arcpy.analysis.Statistics((df_3.iloc[i,2]), (df_3.iloc[i,4]), [[\"POP20\", \"SUM\"]], [\"STATEFP20\", \"COUNTYFP20\"])\n",
    "    print(f\"{df_3.iloc[i,4]}\")\n",
    "    arcpy.management.AlterField((df_3.iloc[i,4]), \"SUM_POP20\", \"v179_numerator\", \"v179_numerator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join tables or fields and calculate measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the parks_numerator field for each state to the county_[stateFIPS]_totalPop table for each respective state and then calculate the measure (numerator divided by denominator). Joining the numerator field to the table that contains the denominator ensures that no counties are dropped. If no census blocks in a county intersected with a park, that county is not included in the accessPop table and will have a missing value for the measure.\n",
    "\n",
    "Since this is being done state by state, county fipscode (COUNTYFP) can be used as the join field \n",
    "\n",
    "- Join Field tool: https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/join-field.htm \n",
    "- Add Field tool: https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/add-field.htm\n",
    "- Calculate Field tool: https://pro.arcgis.com/en/pro-app/latest/tool-reference/data-management/calculate-field.htm\n",
    "\n",
    "**Created by JH, edited from code written by GL, Last updated 2024-11-22**\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "- loop through joining the numerator field to the county_[stateFIPS]_totalPop table\n",
    "- loop through adding a new field where calculated measure will go\n",
    "- merge all county_[stateFIPS]_totalPop tables together into final measure table\n",
    "- calculate the measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loop: arcpy.management.JoinField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#join numerator field to table with total population - input table is table with total pop field, input join field is county fipscode,\n",
    "#join table is table with pop that has access to parks, join table field is county fipscode, transfer field is parks_numerator\n",
    "#arcpy.management.JoinField(in_data, in_field, join_table, join_field, {fields}, {fm_option}, {field_mapping})\n",
    "\n",
    "for i in range(len(df_3)):\n",
    "    print(f\"{df_3.iloc[i,3]}, {df_3.iloc[i,4]}\")\n",
    "    arcpy.management.JoinField((df_3.iloc[i,3]), \"COUNTYFP20\", (df_3.iloc[i,4]), \"COUNTYFP20\", [\"v179_numerator\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loop: arcpy.management.AddField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add new field\n",
    "#arcpy.management.AddField(in_table, field_name, field_type, {field_precision}, {field_scale}, {field_length}, {field_alias}, {field_is_nullable}, {field_is_required}, {field_domain})\n",
    "\n",
    "for i in range(len(df_3)):\n",
    "    print(f\"{df_3.iloc[i,3]}\")\n",
    "    arcpy.management.AddField((df_3.iloc[i,3]), \"v179_rawvalue\", \"DOUBLE\", None, None, None, \"v179_rawvalue\", \"NULLABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all the tables together before doing the final measure calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merge all county_[stateFIPS]_totalPop tables together \n",
    "#arcpy.management.Merge(inputs, output, {field_mappings}, {add_source})\n",
    "\n",
    "arcpy.management.Merge([\"county_01_totalPop\", \"county_02_totalPop\", \"county_04_totalPop\", \"county_05_totalPop\", \"county_06_totalPop\", \"county_08_totalPop\",\n",
    "                       \"county_09_totalPop\", \"county_10_totalPop\", \"county_11_totalPop\", \"county_12_totalPop\", \"county_13_totalPop\", \"county_15_totalPop\",\n",
    "                       \"county_16_totalPop\", \"county_17_totalPop\", \"county_18_totalPop\", \"county_19_totalPop\", \"county_20_totalPop\", \"county_21_totalPop\",\n",
    "                       \"county_22_totalPop\", \"county_23_totalPop\", \"county_24_totalPop\", \"county_25_totalPop\", \"county_26_totalPop\", \"county_27_totalPop\",\n",
    "                       \"county_28_totalPop\", \"county_29_totalPop\", \"county_30_totalPop\", \"county_31_totalPop\", \"county_32_totalPop\", \"county_33_totalPop\",\n",
    "                       \"county_34_totalPop\", \"county_35_totalPop\", \"county_36_totalPop\", \"county_37_totalPop\", \"county_38_totalPop\", \"county_39_totalPop\",\n",
    "                       \"county_40_totalPop\", \"county_41_totalPop\", \"county_42_totalPop\", \"county_44_totalPop\", \"county_45_totalPop\", \"county_46_totalPop\",\n",
    "                       \"county_47_totalPop\", \"county_48_totalPop\", \"county_49_totalPop\", \"county_50_totalPop\", \"county_51_totalPop\", \"county_53_totalPop\",\n",
    "                       \"county_54_totalPop\", \"county_55_totalPop\", \"county_56_totalPop\"], \"parks_access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After the merge, there are 3,145 counties. New counties in AK are included (02063 and 02066) and a null county in CT (a result of the census block crosswalk not containing the census blocks that were in tracts that have no population). There is no COUNTYFP20 value for this row and the numerator and denominator are 0 - just needs to be deleted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select CT row that has no COUNTYFP value and a numerator and denominator of 0\n",
    "#Parameters were set with the tool interface and the Python command was copied\n",
    "\n",
    "arcpy.management.SelectLayerByAttribute(\n",
    "    in_layer_or_view=\"parks_access\",\n",
    "    selection_type=\"NEW_SELECTION\",\n",
    "    where_clause=\"STATEFP20 = '09' And v179_denominator = 0 And v179_numerator = 0\",\n",
    "    invert_where_clause=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete selected CT row that has no COUNTYFP value and a numerator and denominator of 0\n",
    "#arcpy.management.DeleteRows(in_rows)\n",
    "\n",
    "arcpy.management.DeleteRows(in_rows=\"parks_access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate measure - input is merged table that contains all counties \n",
    "#arcpy.management.CalculateField(in_table, field, expression, {expression_type}, {code_block}, {field_type}, {enforce_domains})\n",
    "\n",
    "arcpy.management.CalculateField(\"parks_access\", \"v179_rawvalue\", \"!v179_numerator! / !v179_denominator!\", \n",
    "                                \"PYTHON3\", None, \"DOUBLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties are assigned a missing value when no park locations have been identified in the ESRI parks datasets. In contrast, counties are assigned a 0% when they have a park location but the county population does not live within the defined buffers of that park.\"\n",
    "\n",
    "**The null values reflect counties where there are no parks (based on our data from Esri USA Parks) - i.e. no census blocks in the county intersect with the buffered areas around a park** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final processing \n",
    "**Last updated by JH 2024-11-25**\n",
    "\n",
    "**Tasks:**\n",
    "- Create a fipscode field, delete the FREQUENCY field, and rename the STATEFP20 and COUNTYFP20 fields\n",
    "- Add in old Connecticut counties and flag field for Connecticut counties\n",
    "- Calculate state and national values\n",
    "- Merge the county, state, and national value datasets together to create the final dataset\n",
    "- Save final dataset to P drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing fields with ArcGIS Pro tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create fipscode field \n",
    "arcpy.management.AddField(\"parks_access\", \"fipscode\", \"TEXT\", None, None, 5, \"fipscode\", \"NULLABLE\")\n",
    "\n",
    "#concatenate STATEFP20 and COUNTYFP20\n",
    "arcpy.management.CalculateField(\"parks_access\", \"fipscode\", \"!STATEFP20! + !COUNTYFP20!\", \n",
    "                                \"PYTHON3\", None, \"TEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#delete FREQUENCY\n",
    "arcpy.management.DeleteField(\"parks_access\", [\"FREQUENCY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename STATEFP20 \n",
    "arcpy.management.AlterField(\"parks_access\", \"STATEFP20\", \"statecode\", \"statecode\")\n",
    "\n",
    "#rename COUNTYFP20 \n",
    "arcpy.management.AlterField(\"parks_access\", \"COUNTYFP20\", \"countycode\", \"countycode\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took the parks_access table at this point and joined it to the 2022 Census 1:500,000 county cartographic boundary national file to create a national map to share with the research team. **Update**: Code was re-run to create parks_access on 2024-11-22, but all datapoints should be the same. An earlier version of the dataset was used to create the initial national map. \n",
    "\n",
    "Dataset still needs state and national values, rows for the old Connecticut counties will null values, and the flag_CT field indicating which CT counties have data available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in old CT counties and flag field for CT\n",
    "**Last updated by JH 2024-11-22**\n",
    "\n",
    "Using pandas library. \n",
    "\n",
    "- Convert parks_access table to a pandas dataframe by saving as a csv and them importing a csv (easiest way to do this based on what I've searched online)\n",
    "- Add flag_CT column\n",
    "- Create dataframe for old CT counties\n",
    "- Merge old CT counties with parks_access measure dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcpy.conversion.TableToTable(in_rows, out_path, out_name, {where_clause}, {field_mapping}, {config_keyword})\n",
    "\n",
    "out_path = r\"\" #filtpath in quotes of wherever you want to store your outputs\n",
    "\n",
    "arcpy.conversion.TableToTable(\"parks_access\", out_path, \"parks_access.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in csv file with measure data\n",
    "\n",
    "data_path = out_path + r\"\\parks_access.csv\"\n",
    "\n",
    "parks_df = pd.read_csv(data_path, dtype={\"fipscode\":str, \"statecode\":str, \"countycode\":str})\n",
    "\n",
    "parks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop OID column\n",
    "\n",
    "parks_df = parks_df.drop(columns = [\"OID_\"])\n",
    "\n",
    "parks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add empty flag_CT column \n",
    "\n",
    "parks_df[\"flag_CT\"] = \" \"\n",
    "\n",
    "parks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#assign \"A\" in flag_CT for new CT counties (planning regions)\n",
    "\n",
    "parks_df['flag_CT'].loc[parks_df['statecode'] == '09'] = 'A'\n",
    "\n",
    "parks_df[parks_df['statecode'] == '09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create df for old CT counties\n",
    "\n",
    "oldCT_df = pd.DataFrame({'countycode': ['001', '003', '005', '007', '009', '011', '013', '015']})\n",
    "oldCT_df['statecode'] = '09'\n",
    "oldCT_df['fipscode'] = oldCT_df['statecode'] + oldCT_df['countycode']\n",
    "oldCT_df['v179_denominator'] = np.nan\n",
    "oldCT_df['v179_numerator'] = np.nan\n",
    "oldCT_df['v179_rawvalue'] = np.nan\n",
    "oldCT_df['flag_CT'] = 'U'\n",
    "\n",
    "oldCT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge old CT counties with parks_access, Access to parks is measure number v179\n",
    "\n",
    "v179_county = pd.concat([parks_df, oldCT_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v179_county.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "\n",
    "v179_county = v179_county.reset_index(drop = True)\n",
    "\n",
    "v179_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sort based on fipscode (sometimes need to run the #reset index and #sort based on fipscodes blocks of code twice)\n",
    "\n",
    "v179_county = v179_county.sort_values('fipscode')\n",
    "\n",
    "v179_county[v179_county['statecode'] == '09']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating state and national values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate national value\n",
    "\n",
    "nat_num = v179_county['v179_numerator'].sum()\n",
    "nat_den =  v179_county['v179_denominator'].sum()\n",
    "\n",
    "v179_nat = pd.DataFrame({\n",
    "    'statecode': '00',\n",
    "    'countycode': '000',\n",
    "    'fipscode': '00000',\n",
    "    'v179_denominator': [nat_den],\n",
    "    'v179_numerator': [nat_num],\n",
    "    'v179_rawvalue': [nat_num / nat_den],\n",
    "    'flag_CT': ' '\n",
    "})\n",
    "\n",
    "v179_nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate state values \n",
    "\n",
    "state_num = v179_county.groupby('statecode')['v179_numerator'].sum().reset_index(name = 'v179_numerator')\n",
    "state_den = v179_county.groupby('statecode')['v179_denominator'].sum().reset_index(name = 'v179_denominator')\n",
    "\n",
    "#join state numerator and denominator dataframes \n",
    "v179_state = pd.merge(\n",
    "    state_num, state_den, how = 'left', on = ['statecode']\n",
    "    )\n",
    "\n",
    "#add other columns \n",
    "v179_state['countycode'] = '000'\n",
    "v179_state['fipscode'] = v179_state['statecode'] + v179_state['countycode']\n",
    "v179_state['v179_rawvalue'] = v179_state['v179_numerator'] / v179_state['v179_denominator']\n",
    "v179_state['flag_CT'] = ' '\n",
    "\n",
    "#show contents of join\n",
    "v179_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .reset_index() with a column name specified is necessary to turn the results of the groupby() into a dataframe. \n",
    "\n",
    "You can check if an object is a dataframe using type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final v179 dataset and save to the P drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking datatypes in each dataframe to be merged together \n",
    "\n",
    "print(\"County:\",\n",
    "     v179_county.dtypes)\n",
    "\n",
    "print(\"State:\",\n",
    "      type(v179_state),\n",
    "      v179_state.dtypes)\n",
    "\n",
    "print(\"National:\",\n",
    "     v179_nat.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine dataframes\n",
    "\n",
    "v179_df = pd.concat([v179_county, v179_state, v179_nat], ignore_index = True)\n",
    "\n",
    "v179_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v179_df = v179_df.sort_values('fipscode')\n",
    "v179_df = v179_df.reset_index(drop = True)\n",
    "\n",
    "v179_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export pandas v179_df as a csv to my files \n",
    "\n",
    "v179_df.to_csv(out_path + r'\\v179.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I tried to bring the .csv file into Pro to then use the Table to SAS tool to save the final dataset as SAS dataset, but Pro was not maintaining leading zeros for the statecode, countycode, and fipscode fields. SAS will be used to save the final dataset as a SAS dataset on the P drive. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
